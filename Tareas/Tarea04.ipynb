{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "128c2773",
   "metadata": {},
   "source": [
    "## Investigue sobre las siguientes características para al menos 5 modelos de lenguaje comerciales (i.e. ChatGPT, Claude, Gemini, etc). Cree una tabla resumen. \n",
    "### 1. ¿Qué es inferencia y entrenamiento, cuál es la diferencia?\n",
    "### 2. Modelo de GPU utilizado/s\n",
    "### 3. Costo del hardware (costo GPU x número de GPUs) en inferencia y entrenamiento\n",
    "### 4. Tiempo de entrenamiento\n",
    "### 5. Consumo energético (watts) en inferencia y entrenamiento. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce94eb5",
   "metadata": {},
   "source": [
    "## 1. Diferencia principal\n",
    "| Aspecto   | **Entrenamiento**          | **Inferencia**             |\n",
    "| :-------- | :------------------------- | :------------------------- |\n",
    "| Propósito | Enseñar al modelo          | Usar el modelo entrenado   |\n",
    "| Qué hace  | Ajusta los pesos y aprende | Genera texto o respuestas  |\n",
    "| Recursos  | Altísimos (miles de GPUs)  | Bajos (algunas GPUs o CPU) |\n",
    "| Duración  | Semanas o meses            | Segundos                   |\n",
    "| Ejemplo   | Crear ChatGPT              | Usar ChatGPT               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b19509",
   "metadata": {},
   "source": [
    "## 2. Modelo de GPU utilizado/s\n",
    "| **Modelo de lenguaje** | **Empresa / Desarrollador** | **GPU usada para entrenamiento**    | **GPU usada para inferencia (uso diario)**     | **Observaciones**                                                                          |\n",
    "| :--------------------- | :-------------------------- | :---------------------------------- | :--------------------------------------------- | :----------------------------------------------------------------------------------------- |\n",
    "| **ChatGPT-5 (GPT-5)**  | OpenAI / Microsoft Azure    | **NVIDIA H100 SXM (80 GB)**         | **NVIDIA A100 / H100**                         | Utiliza clusters de miles de H100 en servidores Azure; A100 para despliegues más ligeros.  |\n",
    "| **Claude 3.5 (Opus)**  | Anthropic                   | **NVIDIA A100 80 GB**               | **A100 / H100**                                | Emplea arquitectura Mixture-of-Experts (MoE) para reducir consumo y costo.                 |\n",
    "| **Gemini 1.5 Pro**     | Google DeepMind             | **TPU v5p (propietaria de Google)** | **TPU v5p / TPU v5e**                          | Google usa sus propios chips Tensor Processing Unit en lugar de GPU.                       |\n",
    "| **Llama 3 (70B)**      | Meta AI                     | **NVIDIA H100 SXM**                 | **A100 / H100 / RTX 4090 (versiones locales)** | Entrenamiento distribuido en clusters de H100; versiones open-source usan GPUs de consumo. |\n",
    "| **Mistral Large 2024** | Mistral AI                  | **NVIDIA A100 80 GB**               | **A100 / H100 / Cloud GPUs**                   | Modelo optimizado para eficiencia energética y menor costo.                                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f400c9",
   "metadata": {},
   "source": [
    "## 3. Costo del hardware (costo GPU x número de GPUs) en inferencia y entrenamiento\n",
    "| **Modelo de lenguaje**               | **GPU / TPU utilizada**   | **Cantidad aprox. de GPUs (entrenamiento)** | **Costo por GPU (USD)** |  **Costo total estimado entrenamiento (USD)** | **Cantidad aprox. de GPUs (inferencia activa)** |  **Costo total estimado inferencia (USD)** |\n",
    "| :----------------------------------- | :------------------------ | :-----------------------------------------: | :---------------------: | :---------------------------------------------: | :---------------------------------------------: | :------------------------------------------: |\n",
    "| **ChatGPT-5 (OpenAI)**               | NVIDIA **H100 SXM 80 GB** |                    25 000                   |     25 000 – 30 000     |           ≈ **US $625 – 750 millones**          |                  3 000 – 5 000                  |          ≈ **US $75 – 125 millones**         |\n",
    "| **Claude 3.5 (Anthropic)**           | NVIDIA **A100 80 GB**     |                    10 000                   |     15 000 – 20 000     |           ≈ **US $150 – 200 millones**          |                  1 000 – 2 000                  |          ≈ **US $15 – 40 millones**          |\n",
    "| **Gemini 1.5 Pro (Google DeepMind)** | **TPU v5p** (propietaria) |                    20 000                   |     ~12 000 – 15 000    |           ≈ **US $240 – 300 millones**          |                  2 000 – 4 000                  |          ≈ **US $24 – 60 millones**          |\n",
    "| **Llama 3 (70B) (Meta AI)**          | NVIDIA **H100 SXM**       |                    16 000                   |          25 000         |              ≈ **US $400 millones**             |                  1 000 – 1 500                  |          ≈ **US $25 – 40 millones**          |\n",
    "| **Mistral Large (2024)**             | NVIDIA **A100 80 GB**     |                    2 000                    |          15 000         |              ≈ **US $30 millones**              |                    300 – 500                    |         ≈ **US $4.5 – 7.5 millones**         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca71515d",
   "metadata": {},
   "source": [
    "## 4. Tiempo de entrenamiento\n",
    "| **Modelo de lenguaje**   | **Empresa**              | **Hardware utilizado**    | **Cantidad aprox. de GPUs / TPUs** |  **Tiempo estimado de entrenamiento** | **Notas técnicas relevantes**                                                                                                   |\n",
    "| :----------------------- | :----------------------- | :------------------------ | :--------------------------------: | :-------------------------------------: | :------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| **ChatGPT-5 (OpenAI)**   | OpenAI / Microsoft Azure | NVIDIA **H100 SXM 80 GB** |            ~25 000 GPUs            |    **≈ 85–100 días** (3 meses aprox.)   | Entrenamiento distribuido en clústeres Azure; mezcla de datos textuales, código y RLHF (refuerzo con retroalimentación humana). |\n",
    "| **Claude 3.5 (Opus)**    | Anthropic                | NVIDIA **A100 80 GB**     |            ~10 000 GPUs            |    **≈ 55–65 días** (2 meses aprox.)    | Entrenamiento intensivo con optimización MoE (Mixture-of-Experts), que reduce tiempo y consumo.                                 |\n",
    "| **Gemini 1.5 Pro**       | Google DeepMind          | **TPU v5p**               |            ~20 000 TPUs            |             **≈ 75–85 días**            | Entrenamiento masivo en centros de datos de Google; uso de datos multimodales (texto, imagen, audio).                           |\n",
    "| **Llama 3 (70B)**        | Meta AI                  | NVIDIA **H100 SXM**       |            ~16 000 GPUs            |              **≈ 60 días**              | Entrenamiento open-source de 15 billones de tokens; optimización con PyTorch FSDP.                                              |\n",
    "| **Mistral Large (2024)** | Mistral AI               | NVIDIA **A100 80 GB**     |             ~2 000 GPUs            |             **≈ 40–45 días**            | Modelo más pequeño y eficiente; menor dataset y arquitectura compacta.                                                          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25afae48",
   "metadata": {},
   "source": [
    "## 5. Consumo energético (watts) en inferencia y entrenamiento. \n",
    "| **Modelo de lenguaje**   | **GPU / TPU usada**         |  **Consumo por unidad (W)** |  **Nº GPUs/TPUs entrenamiento** |    **Consumo total estimado entrenamiento**   |  **Nº GPUs/TPUs inferencia activa** |  **Consumo total inferencia (estimado)** |\n",
    "| :----------------------- | :-------------------------- | :--------------------------: | :-------------------------------: | :---------------------------------------------: | :-----------------------------------: | :---------------------------------------: |\n",
    "| **ChatGPT-5 (OpenAI)**   | NVIDIA **H100 SXM (80 GB)** |             700 W            |               25 000              |  ≈ **9 GWh** (≈ 90 días × 25 000 GPUs × 0.7 kW) |              3 000–5 000              |  ≈ **2–3 MWh/día** durante operación 24/7 |\n",
    "| **Claude 3.5 (Opus)**    | NVIDIA **A100 80 GB**       |             600 W            |               10 000              |  ≈ **3 GWh** (≈ 60 días × 10 000 GPUs × 0.6 kW) |              1 000–2 000              |           ≈ **0.8–1.5 MWh/día**           |\n",
    "| **Gemini 1.5 Pro**       | **TPU v5p (Google)**        |             500 W            |               20 000              |  ≈ **6 GWh** (≈ 80 días × 20 000 TPUs × 0.5 kW) |              2 000–4 000              |             ≈ **1–2 MWh/día**             |\n",
    "| **Llama 3 (70B)**        | NVIDIA **H100 SXM**         |             700 W            |               16 000              |  ≈ **5 GWh** (≈ 60 días × 16 000 GPUs × 0.7 kW) |              1 000–1 500              |            ≈ **0.6–1 MWh/día**            |\n",
    "| **Mistral Large (2024)** | NVIDIA **A100 80 GB**       |             600 W            |               2 000               | ≈ **0.7 GWh** (≈ 45 días × 2 000 GPUs × 0.6 kW) |                300–500                |           ≈ **0.1–0.2 MWh/día**           |\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
